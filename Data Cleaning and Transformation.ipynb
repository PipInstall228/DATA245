{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f09cb",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged_dataset_not_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['County', 'Start Date and Time', 'End Date and Time', 'Duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86882382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da965f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Land Cover'] = df['Land Cover'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5cf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Land Cover'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Maximum Temperature'])\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa673ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df['Acres Burned'].isna().sum()\n",
    "print(f\"Number of missing values in the 'Acres Burned' column: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d319cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Acres Burned', 'Dew Point', 'Cloud Cover', 'Relative Humidity', 'Solar Radiation', \n",
    "                       'Solar Energy', 'PDSI', 'NDVI'])\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfede527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n",
    "# By looking at the minimum and maximum values of each variable, there does not seem to be \n",
    "# any errors in the data, given the nature of the data (weather, drought index, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in the missing wind gust values with the corresponding wind speed (since according to the \n",
    "# Weather Crossing Documentation, a missing value means that the wind gust was not significantly\n",
    "# greater than the wind speed)\n",
    "\n",
    "df['Wind Gust'] = df['Wind Gust'].fillna(df['Wind Speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965814b1",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Wildfire Severity score using 3 different metrics\n",
    "\n",
    "df['Acres_Burned_Normalized'] = (df['Acres Burned'] - df['Acres Burned'].min()) / (df['Acres Burned'].max() - df['Acres Burned'].min())\n",
    "\n",
    "df['Wildfire_Scale_Acres_Normalized'] = pd.cut(df['Acres_Burned_Normalized'], bins=[0, 0.2, 0.4, 0.6, 0.8, 1], labels=[1, 2, 3, 4, 5], include_lowest=True)\n",
    "df['Wildfire_Scale_Acres_Quantiles'] = pd.qcut(df['Acres Burned'], 5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Defining the scale similar to the NWCG class scale (https://www.nwcg.gov/term/glossary/size-class-of-fire)\n",
    "# Did not include the original Class A (<1/4 acres), for instance Class B in the NWCG is Class \"A\",\n",
    "# Class C in the NWCG is Class \"B\", and so forth in this case \n",
    "\n",
    "def assign_class(acres):\n",
    "    if acres > (1/4) and acres < 10:\n",
    "        return 'A'\n",
    "    elif acres >= 10 and acres < 100:\n",
    "        return 'B'\n",
    "    elif acres >= 100 and acres < 300:\n",
    "        return 'C'\n",
    "    elif acres >= 300 and acres < 1000:\n",
    "        return 'D'\n",
    "    elif acres >= 1000 and acres < 5000:\n",
    "        return 'E'\n",
    "    elif acres >= 5000:\n",
    "        return 'F'\n",
    "\n",
    "df['Severity_Class'] = df['Acres Burned'].apply(assign_class)\n",
    "\n",
    "# Drop the 'Acres_Burned_Normalized' column\n",
    "df = df.drop(columns=['Acres_Burned_Normalized'])\n",
    "\n",
    "\n",
    "median_acres = df['Acres Burned'].median()\n",
    "\n",
    "df['Wildfire_Scale_Acres_Binary'] = np.where(df['Acres Burned'] <= median_acres, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'Acres Burned' column\n",
    "\n",
    "df = df.drop(columns=['Acres Burned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b69d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31348880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the variance inflation predictor of the predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2283a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8491d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Wildfire_Scale_Acres_Quantiles', 'Wildfire_Scale_Acres_Binary', 'Wildfire_Scale_Acres_Normalized'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Name', 'Date', 'Latitude', 'Longitude', 'Severity_Class'])\n",
    "y = df['Severity_Class']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "variables_to_remove_list = []\n",
    "\n",
    "def recursive_feature_elimination_rf(data, target, n_features_to_select):\n",
    "    global variables_to_remove_list\n",
    "    \n",
    "    estimator = RandomForestClassifier()\n",
    "    selector = RFE(estimator, n_features_to_select=n_features_to_select)\n",
    "    selector = selector.fit(data, target)\n",
    "    \n",
    "    selected_features = data.columns[selector.get_support()]\n",
    "    dropped_features = data.columns[~selector.get_support()]\n",
    "    \n",
    "    # Update the global list with the dropped features\n",
    "    variables_to_remove_list.extend(dropped_features)\n",
    "    \n",
    "    print(\"Dropped features:\", list(dropped_features))\n",
    "    \n",
    "    return data.loc[:, selected_features]\n",
    "\n",
    "n_features_to_select = 10  \n",
    "reduced_data = recursive_feature_elimination_rf(X, y, n_features_to_select)\n",
    "\n",
    "df = df.drop(columns = variables_to_remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d86da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the dataframe before normalizing the variables\n",
    "\n",
    "df.to_csv(\"transformed_dataset_pre-normalization.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the predictor variables using min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "original_X_variable_list = ['Maximum Temperature',\n",
    "       'Minimum Temperature', 'Temperature', 'Dew Point', 'Precipitation',\n",
    "       'Wind Speed', 'Wind Gust', 'Wind Direction', 'Cloud Cover',\n",
    "       'Relative Humidity', 'Solar Radiation', 'Solar Energy', 'PDSI', 'NDVI', 'Land Cover',\n",
    "       'Elevation', 'Slope']\n",
    "\n",
    "\n",
    "new_X_variable_list = [item for item in original_X_variable_list if item not in variables_to_remove_list]\n",
    "\n",
    "print(new_X_variable_list)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[new_X_variable_list] = scaler.fit_transform(df[new_X_variable_list])\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e9d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb137b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"transformed_dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c122ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
